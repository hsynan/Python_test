{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c13489-9878-4e08-bce8-046bb7c54157",
   "metadata": {},
   "source": [
    "# SOM/HAC implementation using SUSI library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee7fab-2c0e-4aa1-b63a-ff5fc6769c3d",
   "metadata": {},
   "source": [
    "In this document, the SUSI lib is going to be used in order to provide an example of usage of the Self Organising Maps algorithm. \n",
    "\n",
    "Can do supervised, semi-supervised, and unsupervised classification\n",
    "\n",
    "Links: \n",
    "* https://pypi.org/project/susi/\n",
    "* https://github.com/felixriese/susi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5303e93f-d8e2-47e7-a3dd-73b615aa4136",
   "metadata": {},
   "source": [
    "Installing the library to computer:\n",
    "\n",
    "1) From command line: **pip install susi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0182d6-cfdf-40ef-876e-0ac4ab7f2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import susi\n",
    "from susi.SOMPlots import plot_nbh_dist_weight_matrix, plot_umatrix\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sompy.sompy import SOMFactory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn_som.som import SOM\n",
    "from pandas import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1002f35-0847-4360-b3a0-e6e2960736be",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Data is loaded into the local environment as a numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07b44b-b07a-471b-add8-be6a17a19070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_all_nonan.csv\")\n",
    "\n",
    "df = df[[\"lat\",\"lon\",\"date\",\"datetime\",\"depth\",\"temp\",\"sal\",\"source\",\"SA\",\"CT\",\"rho\",\"mlp2\",\n",
    "         \"spiciness0\",\"alpha\",\"beta\",\"month\",\"tempAnomalies\",\"salAnomalies\",\"year\"]]\n",
    "clustering_vars = [\"lat\",\"lon\",\"mlp2\",\"spiciness0\",\"tempAnomalies\",\"salAnomalies\"]\n",
    "df = df.fillna(0)\n",
    "data = df[clustering_vars].values\n",
    "N = 500\n",
    "data = data[:N]\n",
    "names = clustering_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b7c4ee-0d0f-4ec0-80ae-bb77ac545801",
   "metadata": {},
   "source": [
    "### SOM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5aae28-dc0d-44ae-9d2d-7257c7596f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "msz = [20,25]\n",
    "som = susi.SOMClustering(\n",
    "    n_rows=msz[0],\n",
    "    n_columns=msz[1]\n",
    ")\n",
    "X_transformed = som.fit_transform(data)\n",
    "#som.fit(X_transformed)\n",
    "print(\"SOM fitted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a05468-9743-4260-a975-9b317c938247",
   "metadata": {},
   "source": [
    "### Quality Measures\n",
    "\n",
    "To check the quality of the map we look for\n",
    " 1) accuracy in the data representation (using average quantization error\n",
    "2)  accuracy in representing the data set topology (using the topographic error measure\n",
    "For quantifying the error of the approximation, 2 metrics should be computed: \n",
    "\n",
    "- **The quantization error**: average distance between each data vector and its BMU.\n",
    "- **The topographic error**: the proportion of all data vectors for which first and second BMUs are not adjacent units.\n",
    "\n",
    "A rule of thumb is to generate several models with different parameters and choose the one which, having a topographic error very near to zero, has the lowest quantization error. It is important to hold the topographic error very low in order to make the components smooth and easy to understand. ts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02657e10-b9d0-4609-b8b5-83e1a41d646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qe = som.get_quantization_error(data)\n",
    "print('The quantization error is ' + str(qe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159356e-03aa-429c-8b40-fa8cfcb3fd6c",
   "metadata": {},
   "source": [
    "## Visualization of SOM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ef137d-ed68-48f3-94c4-fe9875a4106b",
   "metadata": {},
   "source": [
    "### Components map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c96c50-ddcb-43bc-ab05-1e1eb1854df9",
   "metadata": {},
   "source": [
    "#### No component planes visualization available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1841b257-f2c6-48df-849b-ae09aa16c7e3",
   "metadata": {},
   "source": [
    "### Hits map\n",
    "Visualize SOM nodes by density, each node displays how many input vectors are mapped onto each SOM node\n",
    "\n",
    "NOTE: BMUs are given as a location (row,column), not the number of the node (1:msz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f3e2f-4c80-4e09-9269-66cbf6337313",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmu = som.get_bmus(data)\n",
    "plt.hist2d([x[0] for x in bmu], [x[1] for x in bmu])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23edd2fc-b68a-4a7d-a5ed-4cbcefd989db",
   "metadata": {},
   "source": [
    "### U-matrix\n",
    "The \"U-matrix\", or \"distance matrix\" shows the euclidean distances between neighboring units - therefore visualizes the cluster structure of the map. High values on the U-matrix means large distances between neighboring units and thus indicate cluster borders. Clusters typically have uniform areas of low values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9f528-8565-46c4-b2a7-0261953b9fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "umat = som.get_u_matrix()\n",
    "plt.imshow(np.squeeze(umat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c706d8-c8ce-44cf-a451-42dbf270ad3e",
   "metadata": {},
   "source": [
    "### Visualize SOM \"clusters\" on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ff057-84f7-43e6-9473-3de962f6e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to figure this out...\n",
    "#need to assign numbers to each node, and then match up with the bmus (row,column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac31a1-a5be-4584-91d5-38dc5db725ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = som.get_clusters(data)\n",
    "clus_nds = []\n",
    "for x in range(499):\n",
    "    nd = som.get_datapoints_from_node(nodes[x])\n",
    "    clus_nds.append(nd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed86fb0-7e0c-4ea8-9362-186ed5814933",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ['temp','sal']\n",
    "data_ts = df[ts].values\n",
    "data_ts = data_ts[:N]\n",
    "\n",
    "#cluster data into 500 arrays (each for one node)\n",
    "dat_ts = []\n",
    "for x in range(499):\n",
    "    d = data_ts[clus_nds[x]]\n",
    "    dat_ts.append(d)\n",
    "\n",
    "#colors = plt.cm.jet(np.linspace(0,1,n))\n",
    "for x in range(499):\n",
    "    plt.scatter(dat_ts[x][0], dat_ts[x][1], c=node_num[x], cmap='rainbow', s=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff44b06-589f-4bcb-b152-239bbeba35e1",
   "metadata": {},
   "source": [
    "## Hierarchical Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cae433-1e15-4e0a-aafe-bc3b08b11f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "clustering = linkage(nodes, method=\"average\", metric=\"euclidean\")\n",
    "dendrogram(clustering)\n",
    "plt.show()\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
    "from scipy.cluster.hierarchy import cut_tree\n",
    "import seaborn as sns\n",
    "cluster_labels = cut_tree(clustering, n_clusters=6).reshape(-1, )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e6b41dfc-3aa2-4475-a6a1-18fbabcb34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodez = np.array(nodes) #turn nodes from list to np array \n",
    "un_nodes = np.unique(nodez, axis=0,  return_counts=True) # find unique values (each one being a node) \n",
    "num_reps = un_nodes[1] #get the number of times each node was repeated \n",
    "# repeat dummy variable the same amount of times as num_reps \n",
    "node_num = []\n",
    "nn = len(un_nodes[0])\n",
    "for x in range(nn):\n",
    "    nd = np.tile(x, (num_reps[x], 1))\n",
    "    node_num.append(nd) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a153a78-b4c2-4f0f-a2e7-11c77918ed95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0],\n",
       "        [ 0,  5],\n",
       "        [ 0, 10],\n",
       "        [ 0, 11],\n",
       "        [ 0, 12],\n",
       "        [ 0, 13],\n",
       "        [ 0, 18],\n",
       "        [ 0, 19],\n",
       "        [ 0, 21],\n",
       "        [ 1,  5],\n",
       "        [ 1, 10],\n",
       "        [ 2, 11],\n",
       "        [ 3,  4],\n",
       "        [ 3,  8],\n",
       "        [ 3, 14],\n",
       "        [ 3, 24],\n",
       "        [ 4,  4],\n",
       "        [ 4,  7],\n",
       "        [ 4,  9],\n",
       "        [ 4, 10],\n",
       "        [ 4, 11],\n",
       "        [ 4, 14],\n",
       "        [ 4, 24],\n",
       "        [ 5,  5],\n",
       "        [ 5,  8],\n",
       "        [ 5, 10],\n",
       "        [ 5, 11],\n",
       "        [ 5, 24],\n",
       "        [ 6,  0],\n",
       "        [ 6,  3],\n",
       "        [ 6,  4],\n",
       "        [ 6,  5],\n",
       "        [ 6,  6],\n",
       "        [ 6,  7],\n",
       "        [ 6, 10],\n",
       "        [ 6, 24],\n",
       "        [ 7,  0],\n",
       "        [ 7,  5],\n",
       "        [ 7,  6],\n",
       "        [ 7,  8],\n",
       "        [ 7, 10],\n",
       "        [ 7, 12],\n",
       "        [ 8,  0],\n",
       "        [ 8,  5],\n",
       "        [ 8,  6],\n",
       "        [ 8,  7],\n",
       "        [ 9,  0],\n",
       "        [ 9,  5],\n",
       "        [ 9,  9],\n",
       "        [10,  0],\n",
       "        [10,  5],\n",
       "        [10,  8],\n",
       "        [10, 16],\n",
       "        [10, 20],\n",
       "        [10, 21],\n",
       "        [10, 22],\n",
       "        [11,  0],\n",
       "        [11,  5],\n",
       "        [11,  7],\n",
       "        [11,  9],\n",
       "        [11, 23],\n",
       "        [11, 24],\n",
       "        [12,  0],\n",
       "        [12,  6],\n",
       "        [12, 21],\n",
       "        [12, 22],\n",
       "        [13,  0],\n",
       "        [13,  9],\n",
       "        [13, 19],\n",
       "        [13, 20],\n",
       "        [14, 16],\n",
       "        [14, 17],\n",
       "        [14, 18],\n",
       "        [14, 21],\n",
       "        [14, 22],\n",
       "        [14, 23],\n",
       "        [14, 24],\n",
       "        [15, 14],\n",
       "        [15, 15],\n",
       "        [15, 20],\n",
       "        [15, 24],\n",
       "        [16,  0],\n",
       "        [16,  1],\n",
       "        [16,  2],\n",
       "        [16, 13],\n",
       "        [16, 18],\n",
       "        [16, 19],\n",
       "        [17, 18],\n",
       "        [18, 17],\n",
       "        [19,  0],\n",
       "        [19,  2],\n",
       "        [19, 11],\n",
       "        [19, 12],\n",
       "        [19, 15],\n",
       "        [19, 16],\n",
       "        [19, 20],\n",
       "        [19, 21],\n",
       "        [19, 22],\n",
       "        [19, 23],\n",
       "        [19, 24]], dtype=int64),\n",
       " array([17,  2,  2,  1,  2, 20, 13,  1, 20,  5,  1,  1,  1,  1, 15,  7,  1,\n",
       "         1,  1,  4, 11,  1, 15,  1,  1,  1,  2,  2,  1,  2,  3,  4,  1,  1,\n",
       "         2, 44,  2,  1,  2,  1,  1,  1,  2,  2,  1,  3,  1,  5, 19,  2,  1,\n",
       "         1, 18,  3,  3,  2,  3,  3,  1,  1,  2, 12,  2,  1,  1,  1,  3, 17,\n",
       "         4,  3,  7, 12, 15,  2,  2,  1,  5, 10,  2,  2,  1,  2,  2,  1, 16,\n",
       "         2,  1,  1,  4, 15,  1, 12,  1,  8,  9,  9,  4,  2,  1, 17],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_nodes = np.unique(nodez, axis=0,  return_counts=True)\n",
    "un_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0280cde5-ac39-4dcb-b34f-0db01b014d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
